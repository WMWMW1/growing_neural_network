{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DynamicLayer(nn.Module):\n",
    "    def __init__(self, input_features, output_features, init_weights=None, init_bias=None):\n",
    "        super(DynamicLayer, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.output_features = output_features\n",
    "\n",
    "        if init_weights is not None:\n",
    "            self.weights = nn.Parameter(init_weights)\n",
    "        else:\n",
    "            self.weights = nn.Parameter(torch.randn(output_features, input_features))\n",
    "\n",
    "        if init_bias is not None:\n",
    "            self.bias = nn.Parameter(init_bias)\n",
    "        else:\n",
    "            self.bias = nn.Parameter(torch.randn(output_features))\n",
    "    def grow_neurons(self, new_output_features):\n",
    "        # 初始化新增加的权重和偏置为0\n",
    "        additional_weights = nn.Parameter(torch.zeros(new_output_features, self.input_features))\n",
    "        additional_bias = nn.Parameter(torch.zeros(new_output_features))\n",
    "        self.weights = nn.Parameter(torch.cat([self.weights, additional_weights], dim=0))\n",
    "        self.bias = nn.Parameter(torch.cat([self.bias, additional_bias]))\n",
    "        self.output_features += new_output_features\n",
    "    def adjust_input_dim(self, new_input_features):\n",
    "        # 初始化新增加的权重为0\n",
    "        additional_weights = nn.Parameter(torch.zeros(self.output_features, new_input_features - self.input_features))\n",
    "        self.weights = nn.Parameter(torch.cat([self.weights, additional_weights], dim=1))\n",
    "        self.input_features = new_input_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.linear(x, self.weights, self.bias)\n",
    "\n",
    "class FlexibleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlexibleNN, self).__init__()\n",
    "        # 初始化权重和偏置\n",
    "        init_weights1 = torch.randn(5, 10)\n",
    "        init_bias1 = torch.randn(5)\n",
    "        init_weights2 = torch.randn(3, 5)\n",
    "        init_bias2 = torch.randn(3)\n",
    "\n",
    "        self.layer1 = DynamicLayer(10, 5, init_weights=init_weights1, init_bias=init_bias1)\n",
    "        self.layer2 = DynamicLayer(5, 3, init_weights=init_weights2, init_bias=init_bias2)\n",
    "\n",
    "    def grow_network(self):\n",
    "        # 在第一层增加3个神经元\n",
    "        self.layer1.grow_neurons(3)\n",
    "        # 调整第二层以匹配第一层的新输出维度\n",
    "        self.layer2.adjust_input_dim(self.layer1.output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始状态的权重:\n",
      "第一层权重: tensor([[ 0.8004, -0.0968, -0.5970, -0.5206, -0.8678, -0.0295,  0.2575, -0.2446,\n",
      "          0.0412, -0.1789],\n",
      "        [ 0.2142,  0.3899, -1.4569, -0.3474,  1.7738,  0.2485,  1.2093,  0.1862,\n",
      "         -1.1474, -1.8927],\n",
      "        [ 1.5338,  0.9287, -1.7201,  1.7727,  1.4645, -1.6267, -1.2569, -0.7487,\n",
      "          0.9750, -1.1398],\n",
      "        [ 0.5080,  0.3049, -0.2937, -0.3996,  0.6779,  0.2909,  0.2435,  0.2926,\n",
      "         -0.3535, -0.5695],\n",
      "        [ 0.5954, -0.1051,  0.6220, -1.0150,  0.1609,  0.2735,  0.0149,  0.3356,\n",
      "         -0.1692, -1.0205]])\n",
      "第二层权重: tensor([[ 0.8691,  1.3269,  0.2163, -0.7423,  1.4990],\n",
      "        [-0.6174,  2.0788,  1.9671, -0.3645,  1.9890],\n",
      "        [-0.9785, -1.2055,  1.3217,  1.1798, -0.2769]])\n"
     ]
    }
   ],
   "source": [
    "# 示例使用\n",
    "net = FlexibleNN()\n",
    "input_data = torch.randn(1, 10)\n",
    "output = net(input_data)\n",
    "\n",
    "print(\"初始状态的权重:\")\n",
    "print(\"第一层权重:\", net.layer1.weights.data)\n",
    "print(\"第二层权重:\", net.layer2.weights.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.6527, -31.4744,  -3.7672]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.6527, -31.4744,  -3.7672]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 网络增长\n",
    "net.grow_network()\n",
    "\n",
    "# 再次使用相同的输入\n",
    "output = net(input_data)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "增长后的权重:\n",
      "第一层权重: tensor([[ 0.8004, -0.0968, -0.5970, -0.5206, -0.8678, -0.0295,  0.2575, -0.2446,\n",
      "          0.0412, -0.1789],\n",
      "        [ 0.2142,  0.3899, -1.4569, -0.3474,  1.7738,  0.2485,  1.2093,  0.1862,\n",
      "         -1.1474, -1.8927],\n",
      "        [ 1.5338,  0.9287, -1.7201,  1.7727,  1.4645, -1.6267, -1.2569, -0.7487,\n",
      "          0.9750, -1.1398],\n",
      "        [ 0.5080,  0.3049, -0.2937, -0.3996,  0.6779,  0.2909,  0.2435,  0.2926,\n",
      "         -0.3535, -0.5695],\n",
      "        [ 0.5954, -0.1051,  0.6220, -1.0150,  0.1609,  0.2735,  0.0149,  0.3356,\n",
      "         -0.1692, -1.0205],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]])\n",
      "第二层权重: tensor([[ 0.8691,  1.3269,  0.2163, -0.7423,  1.4990,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.6174,  2.0788,  1.9671, -0.3645,  1.9890,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9785, -1.2055,  1.3217,  1.1798, -0.2769,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n增长后的权重:\")\n",
    "print(\"第一层权重:\", net.layer1.weights.data)\n",
    "print(\"第二层权重:\", net.layer2.weights.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
